# FDCR 作弊 vs 去作弊 对比实验报告

## 一、实验设计

### 实验目的
验证FDCR的检测性能是来自**方法本身**还是来自**"作弊"路径**（使用先验知识替换恶意客户端的Fisher信息）。

### 实验配置
- **攻击类型**: base_backdoor (基础后门), dba_backdoor (分布式后门)
- **数据分布**: α=0.9 (接近IID), α=0.1 (高度异构)
- **服务器版本**:
  - `OurRandomControl` (作弊版): 使用`client_type`先验知识，对恶意客户端的Fisher信息用`randn_like`替换
  - `OurRandomControlNoCheat` (去作弊版): 直接使用所有客户端的真实Fisher信息
- **总计**: 2×2×2 = 8个实验

### 关键代码差异

**作弊版 (OurRandomControl.py):**
```python
if not client_type[query_index]:  # 如果是恶意客户端
    query_fish = torch.randn_like(query_fish)  # 用随机噪声替换
```

**去作弊版 (OurRandomControlNoCheat.py):**
```python
# 直接使用客户端提供的真实Fisher信息，不做任何替换
```

---

## 二、实验结果汇总

### 2.1 检测指标对比

| 攻击类型 | α | 版本 | TPR | FPR | Precision | F1 | 完美检测率 |
|---------|---|------|-----|-----|-----------|----|----|
| base_backdoor | 0.9 | 作弊版 | **99.7%** | **0.0%** | **100.0%** | **99.8%** | **99.0%** |
| base_backdoor | 0.9 | 去作弊版 | 21.0% | 36.7% | 19.7% | 20.3% | 1.0% |
| base_backdoor | 0.1 | 作弊版 | **99.3%** | **1.1%** | **97.4%** | **98.3%** | **95.0%** |
| base_backdoor | 0.1 | 去作弊版 | 8.0% | 46.0% | 6.9% | 7.4% | 0.0% |
| dba_backdoor | 0.9 | 作弊版 | **99.7%** | **0.0%** | **100.0%** | **99.8%** | **99.0%** |
| dba_backdoor | 0.9 | 去作弊版 | 47.0% | 29.4% | 40.6% | 43.6% | 4.0% |
| dba_backdoor | 0.1 | 作弊版 | **99.7%** | **1.1%** | **97.4%** | **98.5%** | **96.0%** |
| dba_backdoor | 0.1 | 去作弊版 | 9.3% | 41.9% | 8.7% | 9.0% | 0.0% |

### 2.2 任务指标对比

| 攻击类型 | α | 版本 | ACC (%) | ASR (%) |
|---------|---|------|---------|---------|
| base_backdoor | 0.9 | 作弊版 | 65.83 | **9.17** |
| base_backdoor | 0.9 | 去作弊版 | 64.96 | 49.42 |
| base_backdoor | 0.1 | 作弊版 | 61.76 | **12.20** |
| base_backdoor | 0.1 | 去作弊版 | 44.55 | 58.93 |
| dba_backdoor | 0.9 | 作弊版 | 67.12 | **9.34** |
| dba_backdoor | 0.9 | 去作弊版 | 64.83 | 23.26 |
| dba_backdoor | 0.1 | 作弊版 | 62.41 | **13.03** |
| dba_backdoor | 0.1 | 去作弊版 | 50.95 | 14.85 |

---

## 三、详细分析

### 3.1 检测性能差异

#### 作弊版 vs 去作弊版 检测率对比

| 实验配置 | 作弊版 TPR | 去作弊版 TPR | TPR差异 | 作弊版 FPR | 去作弊版 FPR |
|---------|-----------|-------------|---------|-----------|-------------|
| base_backdoor + α=0.9 | 99.7% | 21.0% | **-78.7%** | 0.0% | 36.7% |
| base_backdoor + α=0.1 | 99.3% | 8.0% | **-91.3%** | 1.1% | 46.0% |
| dba_backdoor + α=0.9 | 99.7% | 47.0% | **-52.7%** | 0.0% | 29.4% |
| dba_backdoor + α=0.1 | 99.7% | 9.3% | **-90.4%** | 1.1% | 41.9% |
| **平均** | **99.6%** | **21.3%** | **-78.3%** | **0.6%** | **38.5%** |

**关键发现**: 
- 去除作弊逻辑后，TPR从平均99.6%暴跌至21.3%，下降了78.3个百分点！
- 同时FPR从0.6%飙升至38.5%，说明去作弊版产生了大量误报！

### 3.2 检测结果详细分析

#### base_backdoor + α=0.9 检测对比

**作弊版** (99/100轮完美检测):
```
Epoch 0: 预测恶意=[7,8], 实际恶意=[7,8,9] (漏检1个)
Epoch 1-99: 预测恶意=[7,8,9], 实际恶意=[7,8,9] (完美检测)
```

**去作弊版** (检测几乎随机):
```
Epoch 0: 预测恶意=[2,3], 实际恶意=[7,8,9] (完全错误)
Epoch 20: 预测恶意=[7,8,9], 实际恶意=[7,8,9] (偶尔正确)
Epoch 22: 预测恶意=[0,1,2,3,6,7,8], 实际恶意=[7,8,9] (大量误报)
...
```

去作弊版的检测结果呈现**随机性**，经常将良性客户端误判为恶意，或漏检真正的恶意客户端。

### 3.3 ASR (攻击成功率) 分析

| 实验配置 | 作弊版 ASR | 去作弊版 ASR | ASR增加 |
|---------|-----------|-------------|---------|
| base_backdoor + α=0.9 | 9.17% | 49.42% | **+40.25%** |
| base_backdoor + α=0.1 | 12.20% | 58.93% | **+46.73%** |
| dba_backdoor + α=0.9 | 9.34% | 23.26% | **+13.92%** |
| dba_backdoor + α=0.1 | 13.03% | 14.85% | +1.82% |

**关键发现**: 
- base_backdoor攻击下，去作弊版的ASR平均增加43.49%
- dba_backdoor攻击下，去作弊版的ASR平均增加7.87%
- DBA攻击在去作弊版下ASR增加较少，可能是因为DBA本身的攻击效果就较弱

### 3.4 ACC (主任务准确率) 分析

| 实验配置 | 作弊版 ACC | 去作弊版 ACC | ACC变化 |
|---------|-----------|-------------|---------|
| base_backdoor + α=0.9 | 65.83% | 64.96% | -0.87% |
| base_backdoor + α=0.1 | 61.76% | 44.55% | **-17.21%** |
| dba_backdoor + α=0.9 | 67.12% | 64.83% | -2.29% |
| dba_backdoor + α=0.1 | 62.41% | 50.95% | **-11.46%** |

**关键发现**:
- α=0.9 (接近IID) 时，ACC差异较小 (~1-2%)
- α=0.1 (高度异构) 时，去作弊版ACC显著下降 (~11-17%)
- 这说明在高度异构场景下，去作弊版的错误检测导致了更多良性客户端被过滤

---

## 四、深度分析

### 4.1 为什么作弊版效果好？

作弊版的核心逻辑：
```python
if not client_type[query_index]:  # 服务器知道谁是恶意的
    query_fish = torch.randn_like(query_fish)  # 用随机噪声替换
```

这意味着：
1. **恶意客户端的Fisher信息被替换为随机噪声**
2. **随机噪声与良性客户端的真实Fisher信息差异巨大**
3. **FINCH聚类可以轻松区分随机噪声和真实Fisher信息**

本质上，作弊版的检测不是基于Fisher信息的语义差异，而是基于**人为制造的噪声差异**。

### 4.2 为什么去作弊版效果差？

去作弊版直接使用所有客户端的真实Fisher信息：
1. **恶意客户端也计算真实的Fisher信息**
2. **恶意客户端的Fisher信息与良性客户端可能非常相似**
3. **FINCH聚类无法有效区分**

这说明：
- Fisher信息本身**不能有效区分**恶意和良性客户端
- FDCR的检测能力主要来自**作弊路径**，而非方法本身

### 4.3 数据异构性的影响

| α值 | 含义 | 去作弊版检测率 | 分析 |
|-----|------|---------------|------|
| 0.9 | 接近IID | 21-47% | 数据分布相似，Fisher信息差异小 |
| 0.1 | 高度异构 | 8-9% | 数据分布差异大，但检测更差 |

**反直觉发现**: 高度异构(α=0.1)时检测率更低！

原因分析：
- 高度异构时，良性客户端之间的Fisher信息差异也很大
- FINCH聚类可能将某些良性客户端误判为恶意
- 导致大量误报，降低了整体检测准确率

---

## 五、结论

### 5.1 核心结论

**FDCR的高检测性能主要来自"作弊"路径，而非方法本身。**

| 指标 | 作弊版 | 去作弊版 | 差异 |
|------|--------|---------|------|
| 平均TPR | 99.6% | 21.3% | -78.3% |
| 平均FPR | 0.6% | 38.5% | +37.9% |
| 平均F1 | 99.1% | 20.1% | -79.0% |
| 平均ASR | 10.94% | 36.62% | +25.68% |
| 平均ACC | 64.28% | 56.32% | -7.96% |

### 5.2 因果证据链

```
作弊版高性能
    ↓
去除作弊逻辑 (删除randn_like替换)
    ↓
检测率从99.59%暴跌至21.33%
    ↓
ASR从10.94%上升至36.62%
    ↓
结论: 性能来自作弊路径，而非方法本身
```

### 5.3 对FDCR论文的质疑

1. **先验知识假设不合理**: 原始实现假设服务器知道哪些客户端是恶意的，这在实际场景中不可能
2. **Fisher信息区分能力有限**: 去除作弊逻辑后，Fisher信息无法有效区分恶意和良性客户端
3. **实验设置可能存在问题**: 论文中报告的高检测率可能依赖于类似的"作弊"机制

### 5.4 建议

1. **重新评估FDCR**: 在不使用先验知识的情况下重新评估其检测能力
2. **改进Fisher信息计算**: 探索更有效的Fisher信息计算方式，使其能真正区分恶意和良性客户端
3. **结合其他特征**: 考虑结合模型更新的其他特征（如梯度范数、更新方向等）进行检测

---

## 六、附录：实验环境

- **数据集**: CIFAR-10
- **模型**: SimpleCNN
- **客户端数量**: 10
- **恶意客户端**: [7, 8, 9] (30%)
- **本地训练轮数**: 10 epochs
- **通信轮次**: 100 rounds
- **学习率**: 0.01

---

*报告生成时间: 2025年12月28日*
